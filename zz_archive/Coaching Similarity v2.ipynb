{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kylieleblancKylie/anaconda/envs/spacy/lib/python3.7/site-packages/sklearn/model_selection/_split.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n"
     ]
    }
   ],
   "source": [
    "import similarity\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from statistics import stdev\n",
    "import seaborn as sns\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall2017_filepath = '/Users/kylieleblancKylie/domino/docsim/data/fall_2017/coaching/'\n",
    "fall2018_filepath = '/Users/kylieleblancKylie/domino/docsim/data/fall_2018/coaching/'\n",
    "spring2018_filepath = '/Users/kylieleblancKylie/domino/docsim/data/spring_2018/coaching/'\n",
    "spring2019_filepath = '/Users/kylieleblancKylie/domino/docsim/data/spring_2019/coaching/'\n",
    "results_filepath = \"/Users/kylieleblancKylie/domino/docsim/results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract text from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fall2018_dict = similarity.make_text_dict(fall2018_filepath, '2018*docx')\n",
    "spring2018_dict = similarity.make_text_dict(spring2018_filepath, '*docx')\n",
    "spring2019_dict = similarity.make_text_dict(spring2019_filepath, '2019*')\n",
    "def create_df(textdict, year, semester):\n",
    "    df = pd.DataFrame.from_dict(data = textdict, orient = 'index').reset_index()\n",
    "    df = df.rename({'index': 'doc', 0: 'text'}, axis = 'columns')\n",
    "    df['year'] = year\n",
    "    df['semester'] = semester\n",
    "    return df\n",
    "fall2018 = create_df(fall2018_dict, 2018, 'fall')\n",
    "spring2018 = create_df(spring2018_dict, 2018, 'spring')\n",
    "spring2019 = create_df(spring2019_dict, 2019, 'spring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2019_119_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:02] Alright.  So, how are you f...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2019_5_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:07] Yeah that can be tough.  I ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018_97_3C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:00] All right, take a deep brea...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018_55_3C_Transcript.docx</td>\n",
       "      <td>Coach:  [0:00:00] Okay, so uhm how do you feel...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018_87_3C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:00] Alright deep breath, it’s o...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018_37_3C Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:00] So, how do you feel about y...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>59-2C.docx</td>\n",
       "      <td>[00:00:00] Coach: What do you think, how do yo...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018_70_3C_Transcript.docx</td>\n",
       "      <td>Coach: [00:00:00]  I’m going to start our time...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>31-2C.docx</td>\n",
       "      <td>[00:00:00] Coach: How do you feel? What do you...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2019_42_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:03] Aside from terrible, before...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             doc  \\\n",
       "118  2019_119_5C_Transcript.docx   \n",
       "152    2019_5_5C_Transcript.docx   \n",
       "29    2018_97_3C_Transcript.docx   \n",
       "6     2018_55_3C_Transcript.docx   \n",
       "31    2018_87_3C_Transcript.docx   \n",
       "12    2018_37_3C Transcript.docx   \n",
       "55                    59-2C.docx   \n",
       "26    2018_70_3C_Transcript.docx   \n",
       "79                    31-2C.docx   \n",
       "138   2019_42_5C_Transcript.docx   \n",
       "\n",
       "                                                  text  year semester  \n",
       "118  Coach:  [00:00:02] Alright.  So, how are you f...  2019   spring  \n",
       "152  Coach:  [00:00:07] Yeah that can be tough.  I ...  2019   spring  \n",
       "29   Coach:  [00:00:00] All right, take a deep brea...  2018     fall  \n",
       "6    Coach:  [0:00:00] Okay, so uhm how do you feel...  2018     fall  \n",
       "31   Coach:  [00:00:00] Alright deep breath, it’s o...  2018     fall  \n",
       "12   Coach:  [00:00:00] So, how do you feel about y...  2018     fall  \n",
       "55   [00:00:00] Coach: What do you think, how do yo...  2018   spring  \n",
       "26   Coach: [00:00:00]  I’m going to start our time...  2018     fall  \n",
       "79   [00:00:00] Coach: How do you feel? What do you...  2018   spring  \n",
       "138  Coach:  [00:00:03] Aside from terrible, before...  2019   spring  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fall2018.append(spring2018)\n",
    "df = df.append(spring2019)\n",
    "df = df.reset_index(drop = True)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create document term matrix for full copus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words extracted from corpus: \n",
      "a, abbi, abil, abl, about, abras, abruptli, absolut, absorb, academ, accept, access, acclim, accomplish, account, accur, acknowledg, across, act, action, activ, actual, ad, add, addit, address, adjust, admir, advantag, advers, advic, advoc, affect, afraid, after, afterward, again, against, aggress, agit, agre, ah, ahead, aim, air, al, alarm, alex, alic, align, alittl, all, allow, allright, almost, along, aloud, alreadi, alright, alrighti, also, alter, altern, although, alway, am, amaz, ambigu, amic, amount, an, anatoli, and, anger, angl, angri, ani, announc, annoy, anoth, answer, anxieti, anxiou, anybodi, anymor, anyon, anyth, anytim, anyway, anywher, apart, appear, appl, appli, applic, appreci, approach, appropri, approxim, are, area, aren, argu, argument, ariel, aris, arm, around, as, asid, ask, aspect, assert, associ, assum, assumpt, at, atmospher, attach, attack, attempt, attend, attent, attitud, attribut, audienc, audio, author, ava, avail, avatar, avoid, awar, away, awesom, awhil, awkward, b, ba, back, background, backpack, bad, bag, bagel, balanc, bang, base, basic, bat, battl, be, beach, bear, beat, beatbox, beauti, becaus, becom, been, beep, befor, began, begin, behav, behavior, behavoir, behind, believ, bell, benefici, benefit, besid, best, bet, better, between, big, bigger, biggest, billion, bingo, bird, bit, bizarr, blah, bless, blow, board, bodi, book, boom, bossi, both, bother, bottom, boundari, box, brain, brainstorm, "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "      <th>term_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018_112_3C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:00] But I’d love to hear from y...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "      <td>[4, 0, 1, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018_96_3C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:00] All right, so take a deep b...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "      <td>[9, 0, 0, 0, 9, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2019_50_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [0:00:05] All right.  So how are you f...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[6, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018_55_3C_Transcript.docx</td>\n",
       "      <td>Coach:  [0:00:00] Okay, so uhm how do you feel...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "      <td>[13, 0, 0, 3, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>104-2C.docx</td>\n",
       "      <td>[00:00:00] Coach: How do you think that went? ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "      <td>[8, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             doc  \\\n",
       "35   2018_112_3C_Transcript.docx   \n",
       "24    2018_96_3C_Transcript.docx   \n",
       "131   2019_50_5C_Transcript.docx   \n",
       "6     2018_55_3C_Transcript.docx   \n",
       "90                   104-2C.docx   \n",
       "\n",
       "                                                  text  year semester  \\\n",
       "35   Coach:  [00:00:00] But I’d love to hear from y...  2018     fall   \n",
       "24   Coach:  [00:00:00] All right, so take a deep b...  2018     fall   \n",
       "131  Coach:  [0:00:05] All right.  So how are you f...  2019   spring   \n",
       "6    Coach:  [0:00:00] Okay, so uhm how do you feel...  2018     fall   \n",
       "90   [00:00:00] Coach: How do you think that went? ...  2018   spring   \n",
       "\n",
       "                                             term_freq  \n",
       "35   [4, 0, 1, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "24   [9, 0, 0, 0, 9, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "131  [6, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "6    [13, 0, 0, 3, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "90   [8, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(df.text)\n",
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer(token_pattern=r'\\b[^\\d\\W]+\\b').build_analyzer()\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "stem_vectorizer = CountVectorizer(analyzer=stemmed_words)\n",
    "\n",
    "vectors = stem_vectorizer.fit_transform(corpus)\n",
    "print(\"Words extracted from corpus: \")\n",
    "for word in stem_vectorizer.get_feature_names()[0:200]:\n",
    "    print(word, end = \", \")\n",
    "count_vect_df = pd.DataFrame(vectors.todense(), columns=stem_vectorizer.get_feature_names())\n",
    "word_freq = count_vect_df.values.tolist()\n",
    "df['term_freq'] = word_freq\n",
    "#df = df.reset_index()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "      <th>term_freq</th>\n",
       "      <th>within_study</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018_82_3C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:00] so how are you feeling the ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "      <td>[18, 0, 0, 3, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.878124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>14-2C.docx</td>\n",
       "      <td>[00:00:00] Coach: So how do you feel about tha...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "      <td>[7, 0, 0, 1, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.864272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2019_42_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:03] Aside from terrible, before...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[6, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.848574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2019_80_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:15] Well, it definitely showed....</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[11, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.861298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2019_114_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:00] How do you feel about, are ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[8, 0, 0, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.853753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             doc  \\\n",
       "38    2018_82_3C_Transcript.docx   \n",
       "60                    14-2C.docx   \n",
       "138   2019_42_5C_Transcript.docx   \n",
       "122   2019_80_5C_Transcript.docx   \n",
       "119  2019_114_5C_Transcript.docx   \n",
       "\n",
       "                                                  text  year semester  \\\n",
       "38   Coach:  [00:00:00] so how are you feeling the ...  2018     fall   \n",
       "60   [00:00:00] Coach: So how do you feel about tha...  2018   spring   \n",
       "138  Coach:  [00:00:03] Aside from terrible, before...  2019   spring   \n",
       "122  Coach:  [00:00:15] Well, it definitely showed....  2019   spring   \n",
       "119  Coach:  [00:00:00] How do you feel about, are ...  2019   spring   \n",
       "\n",
       "                                             term_freq  within_study  \n",
       "38   [18, 0, 0, 3, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.878124  \n",
       "60   [7, 0, 0, 1, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.864272  \n",
       "138  [6, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0.848574  \n",
       "122  [11, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.861298  \n",
       "119  [8, 0, 0, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0.853753  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['within_study'] = np.nan\n",
    "def within_study_mean(df, semester, year):\n",
    "    for maindoc in df[(df.semester == semester) & (df.year == year)].index:\n",
    "        pairwise_sim = []\n",
    "        for doc in df[(df.semester == semester) & (df.year == year)].index:\n",
    "            sim = 1 - spatial.distance.cosine(df.term_freq.loc[maindoc], df.term_freq.loc[doc])\n",
    "            pairwise_sim.append(sim)\n",
    "        average = (sum(pairwise_sim) - 1)/(len(pairwise_sim) - 1) # don't include relationship with self\n",
    "        df.at[maindoc, 'within_study'] = average\n",
    "    return df\n",
    "df = within_study_mean(df, 'fall', 2018)\n",
    "df = within_study_mean(df, 'spring', 2018)\n",
    "df = within_study_mean(df, 'spring', 2019)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "      <th>term_freq</th>\n",
       "      <th>within_study</th>\n",
       "      <th>within_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2019_77_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:02] All right.  So take a seat....</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[15, 0, 0, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.875801</td>\n",
       "      <td>0.837817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018_68_3C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:02] That's okay.  That's totall...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "      <td>[15, 0, 0, 0, 8, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.848047</td>\n",
       "      <td>0.848047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2019_54_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:10] So, you probably heard me c...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[11, 0, 0, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.816194</td>\n",
       "      <td>0.800032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2019_94_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [0:00:00] Well, how do you think that?...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[8, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.841071</td>\n",
       "      <td>0.813137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018_49_3C Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:00] So, how do you think of you...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "      <td>[8, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.849523</td>\n",
       "      <td>0.849523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            doc  \\\n",
       "155  2019_77_5C_Transcript.docx   \n",
       "17   2018_68_3C_Transcript.docx   \n",
       "159  2019_54_5C_Transcript.docx   \n",
       "140  2019_94_5C_Transcript.docx   \n",
       "8    2018_49_3C Transcript.docx   \n",
       "\n",
       "                                                  text  year semester  \\\n",
       "155  Coach:  [00:00:02] All right.  So take a seat....  2019   spring   \n",
       "17   Coach:  [00:00:02] That's okay.  That's totall...  2018     fall   \n",
       "159  Coach:  [00:00:10] So, you probably heard me c...  2019   spring   \n",
       "140  Coach:  [0:00:00] Well, how do you think that?...  2019   spring   \n",
       "8    Coach:  [00:00:00] So, how do you think of you...  2018     fall   \n",
       "\n",
       "                                             term_freq  within_study  \\\n",
       "155  [15, 0, 0, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.875801   \n",
       "17   [15, 0, 0, 0, 8, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0,...      0.848047   \n",
       "159  [11, 0, 0, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,...      0.816194   \n",
       "140  [8, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0.841071   \n",
       "8    [8, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0.849523   \n",
       "\n",
       "     within_context  \n",
       "155        0.837817  \n",
       "17         0.848047  \n",
       "159        0.800032  \n",
       "140        0.813137  \n",
       "8          0.849523  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['within_context'] = np.nan\n",
    "def within_context_mean(df, semester):\n",
    "    for maindoc in df[(df.semester == semester)].index:\n",
    "        pairwise_sim = []\n",
    "        for doc in df[(df.semester == semester)].index:\n",
    "            sim = 1 - spatial.distance.cosine(df.term_freq.loc[maindoc], df.term_freq.loc[doc])\n",
    "            pairwise_sim.append(sim)\n",
    "        average = (sum(pairwise_sim) - 1)/(len(pairwise_sim) - 1) # don't include relationship with self\n",
    "        df.at[maindoc, 'within_context'] = average\n",
    "    return df\n",
    "df = within_context_mean(df, 'fall')\n",
    "df = within_context_mean(df, 'spring')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "      <th>term_freq</th>\n",
       "      <th>within_study</th>\n",
       "      <th>within_context</th>\n",
       "      <th>corpus_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>88-2C.docx</td>\n",
       "      <td>[00:00:01] Coach: Um, so how are you feeling a...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "      <td>[11, 0, 0, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.820355</td>\n",
       "      <td>0.824334</td>\n",
       "      <td>0.810200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2018_59_3C_Transcript.docx</td>\n",
       "      <td>Coach: [00:00:00] So, the first thing I want i...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "      <td>[9, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.855047</td>\n",
       "      <td>0.855047</td>\n",
       "      <td>0.785326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>107-2C.docx</td>\n",
       "      <td>[00:00:01] Coach: How are you feeling?\\n[00:00...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "      <td>[8, 0, 0, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.847645</td>\n",
       "      <td>0.830848</td>\n",
       "      <td>0.804464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2019_94_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [0:00:00] Well, how do you think that?...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[8, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.841071</td>\n",
       "      <td>0.813137</td>\n",
       "      <td>0.807709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018_3_3C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:00] All right.  How did you thi...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "      <td>[11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.796684</td>\n",
       "      <td>0.796684</td>\n",
       "      <td>0.723625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            doc  \\\n",
       "80                   88-2C.docx   \n",
       "40   2018_59_3C_Transcript.docx   \n",
       "100                 107-2C.docx   \n",
       "140  2019_94_5C_Transcript.docx   \n",
       "18    2018_3_3C_Transcript.docx   \n",
       "\n",
       "                                                  text  year semester  \\\n",
       "80   [00:00:01] Coach: Um, so how are you feeling a...  2018   spring   \n",
       "40   Coach: [00:00:00] So, the first thing I want i...  2018     fall   \n",
       "100  [00:00:01] Coach: How are you feeling?\\n[00:00...  2018   spring   \n",
       "140  Coach:  [0:00:00] Well, how do you think that?...  2019   spring   \n",
       "18   Coach:  [00:00:00] All right.  How did you thi...  2018     fall   \n",
       "\n",
       "                                             term_freq  within_study  \\\n",
       "80   [11, 0, 0, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.820355   \n",
       "40   [9, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0.855047   \n",
       "100  [8, 0, 0, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0.847645   \n",
       "140  [8, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0.841071   \n",
       "18   [11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.796684   \n",
       "\n",
       "     within_context  corpus_distance  \n",
       "80         0.824334         0.810200  \n",
       "40         0.855047         0.785326  \n",
       "100        0.830848         0.804464  \n",
       "140        0.813137         0.807709  \n",
       "18         0.796684         0.723625  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['corpus_distance'] = np.nan\n",
    "def corpus_mean(df):\n",
    "    for maindoc in df.index:\n",
    "        pairwise_sim = []\n",
    "        for doc in df.index:\n",
    "            sim = 1 - spatial.distance.cosine(df.term_freq.loc[maindoc], df.term_freq.loc[doc])\n",
    "            pairwise_sim.append(sim)\n",
    "        average = (sum(pairwise_sim) - 1)/(len(pairwise_sim) - 1) # don't include relationship with self\n",
    "        df.at[maindoc, 'corpus_distance'] = average\n",
    "    return df\n",
    "df = corpus_mean(df)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "      <th>term_freq</th>\n",
       "      <th>within_study</th>\n",
       "      <th>within_context</th>\n",
       "      <th>corpus_distance</th>\n",
       "      <th>fall2018tospring2019</th>\n",
       "      <th>spring2018tospring2019</th>\n",
       "      <th>spring2018tofall2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018_4_3C Transcript.docx</td>\n",
       "      <td>Coach:  [0:00] How did you feel that went? [0:...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "      <td>[10, 0, 0, 0, 8, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.866489</td>\n",
       "      <td>0.866489</td>\n",
       "      <td>0.801599</td>\n",
       "      <td>0.790582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018_80_3C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:01] So, I would love to hear wh...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "      <td>[6, 0, 0, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.865850</td>\n",
       "      <td>0.865850</td>\n",
       "      <td>0.802379</td>\n",
       "      <td>0.798824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>96-2C.docx</td>\n",
       "      <td>[00:00:01] Coach: Okay\\n[00:00:07] Coach: I'm ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "      <td>[10, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.843533</td>\n",
       "      <td>0.834981</td>\n",
       "      <td>0.816540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.822249</td>\n",
       "      <td>0.772595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>53-2C.docx</td>\n",
       "      <td>[00:00:00] Coach: So, how do you feel about th...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "      <td>[11, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.844786</td>\n",
       "      <td>0.818968</td>\n",
       "      <td>0.798481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.780527</td>\n",
       "      <td>0.749663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>102-2C.docx</td>\n",
       "      <td>[00:00:01] Coach: Okay.\\n[00:00:05] Coach: Yea...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "      <td>[2, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.777991</td>\n",
       "      <td>0.752438</td>\n",
       "      <td>0.729633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714394</td>\n",
       "      <td>0.675286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018_41_3C Transcript .docx</td>\n",
       "      <td>Coach:  [00:00:00] So, how do you feel about t...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "      <td>[11, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.846108</td>\n",
       "      <td>0.846108</td>\n",
       "      <td>0.805467</td>\n",
       "      <td>0.805620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2019_94_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [0:00:00] Well, how do you think that?...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[8, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.841071</td>\n",
       "      <td>0.813137</td>\n",
       "      <td>0.807709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2019_20_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:04] All right, so come on over....</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[15, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.827789</td>\n",
       "      <td>0.807323</td>\n",
       "      <td>0.797240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>52-2C.docx</td>\n",
       "      <td>[00:00:00] Coach: All right. So Danielle, how ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "      <td>[3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.791841</td>\n",
       "      <td>0.788817</td>\n",
       "      <td>0.782691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784316</td>\n",
       "      <td>0.768093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2019_42_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:03] Aside from terrible, before...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[6, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.848574</td>\n",
       "      <td>0.815882</td>\n",
       "      <td>0.808169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             doc  \\\n",
       "15     2018_4_3C Transcript.docx   \n",
       "1     2018_80_3C_Transcript.docx   \n",
       "114                   96-2C.docx   \n",
       "78                    53-2C.docx   \n",
       "57                   102-2C.docx   \n",
       "33   2018_41_3C Transcript .docx   \n",
       "140   2019_94_5C_Transcript.docx   \n",
       "134   2019_20_5C_Transcript.docx   \n",
       "61                    52-2C.docx   \n",
       "138   2019_42_5C_Transcript.docx   \n",
       "\n",
       "                                                  text  year semester  \\\n",
       "15   Coach:  [0:00] How did you feel that went? [0:...  2018     fall   \n",
       "1    Coach:  [00:00:01] So, I would love to hear wh...  2018     fall   \n",
       "114  [00:00:01] Coach: Okay\\n[00:00:07] Coach: I'm ...  2018   spring   \n",
       "78   [00:00:00] Coach: So, how do you feel about th...  2018   spring   \n",
       "57   [00:00:01] Coach: Okay.\\n[00:00:05] Coach: Yea...  2018   spring   \n",
       "33   Coach:  [00:00:00] So, how do you feel about t...  2018     fall   \n",
       "140  Coach:  [0:00:00] Well, how do you think that?...  2019   spring   \n",
       "134  Coach:  [00:00:04] All right, so come on over....  2019   spring   \n",
       "61   [00:00:00] Coach: All right. So Danielle, how ...  2018   spring   \n",
       "138  Coach:  [00:00:03] Aside from terrible, before...  2019   spring   \n",
       "\n",
       "                                             term_freq  within_study  \\\n",
       "15   [10, 0, 0, 0, 8, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0,...      0.866489   \n",
       "1    [6, 0, 0, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0.865850   \n",
       "114  [10, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.843533   \n",
       "78   [11, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.844786   \n",
       "57   [2, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0.777991   \n",
       "33   [11, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.846108   \n",
       "140  [8, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0.841071   \n",
       "134  [15, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,...      0.827789   \n",
       "61   [3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0.791841   \n",
       "138  [6, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0.848574   \n",
       "\n",
       "     within_context  corpus_distance  fall2018tospring2019  \\\n",
       "15         0.866489         0.801599              0.790582   \n",
       "1          0.865850         0.802379              0.798824   \n",
       "114        0.834981         0.816540                   NaN   \n",
       "78         0.818968         0.798481                   NaN   \n",
       "57         0.752438         0.729633                   NaN   \n",
       "33         0.846108         0.805467              0.805620   \n",
       "140        0.813137         0.807709                   NaN   \n",
       "134        0.807323         0.797240                   NaN   \n",
       "61         0.788817         0.782691                   NaN   \n",
       "138        0.815882         0.808169                   NaN   \n",
       "\n",
       "     spring2018tospring2019  spring2018tofall2018  \n",
       "15                      NaN                   NaN  \n",
       "1                       NaN                   NaN  \n",
       "114                0.822249              0.772595  \n",
       "78                 0.780527              0.749663  \n",
       "57                 0.714394              0.675286  \n",
       "33                      NaN                   NaN  \n",
       "140                     NaN                   NaN  \n",
       "134                     NaN                   NaN  \n",
       "61                 0.784316              0.768093  \n",
       "138                     NaN                   NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def this_to_that_mean(df, this_year, this_semester, that_year, that_semester):\n",
    "    varname = this_semester + str(this_year) + 'to' + that_semester + str(that_year) \n",
    "    for maindoc in df[(df.year == this_year) & (df.semester == this_semester)].index:\n",
    "        pairwise_sim = []\n",
    "        for doc in df[(df.semester == that_semester) & (df.year == that_year)].index:\n",
    "            sim = 1 - spatial.distance.cosine(df.term_freq.loc[maindoc], df.term_freq.loc[doc])\n",
    "            pairwise_sim.append(sim)\n",
    "        average = sum(pairwise_sim)/len(pairwise_sim) \n",
    "        df.at[maindoc, varname] = average\n",
    "    return df\n",
    "df = this_to_that_mean(df, 2018, 'fall', 2019, 'spring')\n",
    "df = this_to_that_mean(df, 2018, 'spring', 2019, 'spring')\n",
    "df = this_to_that_mean(df, 2018, 'spring', 2018, 'fall')\n",
    "df.sample(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results - Within a Single RCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Fall 2018:  0.85\n",
      "[ 0.0184 ]\n",
      "Within Spring 2018:  0.835\n",
      "[ 0.0219 ]\n",
      "Within Spring 2019:  0.846\n",
      "[ 0.0206 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Within Fall 2018: \", round(df[(df.semester == \"fall\") & (df.year == 2018)].within_study.mean(), ndigits = 3))\n",
    "print(\"[\", round(df[(df.semester == \"fall\") & (df.year == 2018)].within_study.std(), ndigits = 4), \"]\")\n",
    "print(\"Within Spring 2018: \", round(df[(df.semester == \"spring\") & (df.year == 2018)].within_study.mean(), ndigits = 3))\n",
    "print(\"[\", round(df[(df.semester == \"spring\") & (df.year == 2018)].within_study.std(), ndigits = 4), \"]\")\n",
    "print(\"Within Spring 2019: \", round(df[(df.semester == \"spring\") & (df.year == 2019)].within_study.mean(), ndigits = 3))\n",
    "print(\"[\", round(df[(df.semester == \"spring\") & (df.year == 2019)].within_study.std(), ndigits = 4), \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "bins = np.linspace(0.7, 1, num = 40)\n",
    "plt.hist(df[(df.semester == \"fall\") & (df.year == 2018)].within_study, bins)\n",
    "plt.title(\"Fall 2018 Feedback Scenario\")\n",
    "plt.xlabel('Pairwise Cosine Similarity')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.savefig(results_filepath + \"fall2018hist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.hist(spring2019_within, bins, color = \"green\", label = \"Spring 2019 Behavior Scenario\", alpha = .5)\n",
    "plt.hist(spring2019_between, bins, color = \"yellow\", label = \"Spring to Fall\", alpha = .5)\n",
    "plt.legend()\n",
    "plt.title(\"Spring Coaching Similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall Outlier Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Coach:  [0:00:00] So, how’d you think it went? [00:00:01]\\nCoach:  [0:00:24] Okay.  So, I’m glad you’re feeling good about it.  Hopefully we can like in this little bit of time we have make you feel even more prepared for the next time.  So first off, I just want to comment on maintaining enthusiasm because I know that's hard when you're interacting with these avatars.  Second off, as you pointed out, you were constantly probing them to go back to the text, provide explanation to support their claims, what in the text makes you think that, can you find that in there, those are all really great things so keep doing that.\\nCoach:  [00:02:18] So what I think would be um, advantageous moving forward--so you have those two moments where you were scaffolding –  [00:02:29]\\nCoach:  [00:02:30]  - for student comprehension, but once they like, change their answer, give them the high quality descriptive feedback as well.  Like so do like you did with Savannah.  So, make sure that you're giving them time to or you’re putting out behavior – [00:02:49]\\nCoach:  [00:02:50] - that you really like that they did well and why they did that.  Okay? [00:02:54]\\nCoach: [00:02:55] So um let's see.  So let’s think back to with Ethan for instance.  Once he went back and he revived his answer. [00:03:08]\\nCoach: [00:03:08] What would be an acceptable thing or feedback that you might be saying to him? [00:03:13]\\nCoach: [00:03:15] So he was the one that said was like “excited”. [00:03:18]\\nCoach: [00:03:33] Good. Okay.  So talk to me a little bit about how that type of feedback might be preferable than just kind of like moving on and you providing like a summary of like, you know what I mean? [00:03:50]\\nCoach: [00:04:27] Good. Okay so given our limited time, I kind of like skipped it.  Okay let's think about um in question two with Ava.  What might be--when Ava goes back and changes her response after you probed her for text-based evidence, you kind of scaffolded and she says, well you know, she might be, I guess she's something else.  What might be something you would say with Ava? [00:04:52]\\nCoach: [00:05:13] Awesome. [00:05:14]\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[df.semester == 'fall']['within_study'].idxmin(), 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall Most Average Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coach:  [00:00:00] so how are you feeling the first time [00:00:02]? \\nCoach:  [00:00:10] good, good.  So, I\\'m glad that you\\'re feeling great or good about it.  Hopefully, we can get you to feel even better for the next time.  So first of all, I just want to say I appreciate that you maintain enthusiasm in the simulator.  I know that\\'s hard when you\\'re like trying to interact with these avatars such students.  Also, I want to say that I really appreciated the way that you were constantly probing for evidence.  When a student would make a claim, you would say, \"What makes you think that?  What in the text?\" [00:00:35]\\nCoach:  [00:00:36] And then you were also facilitating and pointing them to places in the text.  So I think that as we move forward and we try to make the next simulation a little stronger, it might be best for us to focus on scaffolding for student comprehension. [00:00:50]\\nCoach:  [00:00:51] So sometimes students um can struggle to comprehend the text that they\\'re reading.  They can make claims that we know that aren\\'t supported in the text, can be outright refuted.  So we really want to focus on the feedback that we provide them to help support them in making sense and also revising their response.  So can you think of a time during the last simulation where a student gave an answer that was not accurate [00:01:16]? \\nCoach:  [00:01:38] good.  So I\\'m glad that you\\'re putting out--those out.  Let\\'s focus on one Eva for the second question.  So she said that Lisa is the new student intern.  Why is that not a valid claim [00:01:50]? \\nCoach:  [00:01:54] exactly.  So think about what you\\'re already doing well.  What could you do to like stick with Eva to help her realize that that\\'s a misconception?  Because that\\'s not really what\\'s happening right in the question like who is she really?  So what might you be able to do?  What make - what kind of feedback might you be able to give that would help us know that that is a misconception [00:02:18]?\\nCoach:  [00:02:23] perfect.  Perfect [00:02:23].\\nCoach:  [00:02:30] Right?  So we know that with Ava’s responses in regard to the question number two, and with who Lisa really is.  So what I going to reference or to this place in the text talks about if Pismo was so smart, would he be able to tell who she really was, would he know that her cover as a student intern was all a lie?  So maybe one of the best things to do would be to reference Eva, and other students to revisit this piece of the text and then ask Eva, \"Eva, after looking at this passage, would you want to revise your answer?\" [00:03:05] \\nCoach:  [00:03:06] And hopefully she would.  And at that point you just want to make sure you\\'re continuing to get high quality descriptive feedback like, \"Eva, I really like how you went back in the text, you know, after spending more time with it, you did something that really good readers do.  You make revisions to readers,\" those sorts of things.  And just keep that in mind that you - that would also be a good strategy moving forward for Ethan as well. [00:03:30] \\nCoach:  [00:03:32] So how might the feedback that we just talked about pointing them back to the text, having them kind of grapple at everything.  How might that be better than kind of leaving it open to like moving on to other students and seeing if they have a response [00:03:47]?\\nCoach:  [00:03:48] Right.  Yeah, you\\'ve [00:03:49] -\\nCoach:  [00:03:52] right.  Is there like [00:03:53] -\\nCoach:  [00:03:57] so if you don\\'t address it in the moment, you\\'re kind of really just hoping, right then that the conversation gets back to that and that the students - the other students kind of point you in that direction and that Eva will, you know, hopefully realize that that was a misconception .  But if you address it hadn\\'t went, then you\\'ll have dealt with it.  Because you don\\'t want - well, what you don’t want to happen is for students to leave thinking that, \"Oh, it could\\'ve been - she could have been a student intern or she could\\'ve been a spy she could have been a reporter.\"  Okay.  So let\\'s do a brief practice.  So, let\\'s see.  So I\\'ll ask - so I\\'m going to ask you a question and then you can respond.  So, how about if I said that Lisa is feeling angry when - when the lie detector results I brought up, what would you say to me [00:04:58]? \\nCoach:  [00:05:07] you could ask why they think that [00:05:09].\\nCoach:  [00:05:09] yeah [00:05:10].  \\nCoach:  [00:05:11] okay, great [00:05:12].'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[df.semester == 'fall']['within_study'].idxmax(), 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results - Replication where context varies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.806623047029445"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corpus_distance.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023279454495437637"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corpus_distance.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between Fall 2018 and Spring 2019:  0.7943\n",
      "[ 0.0311 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Between Fall 2018 and Spring 2019: \", round(df[(df.semester == \"fall\") & (df.year == 2018)].fall2018tospring2019.mean(), ndigits = 4))\n",
    "print(\"[\", round(df[(df.semester == \"fall\") & (df.year == 2018)].fall2018tospring2019.std(), ndigits = 4), \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between Spring 2018 and Spring 2019:  0.8087\n",
      "[ 0.0267 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Between Spring 2018 and Spring 2019: \", round(df[(df.semester == \"spring\") & (df.year == 2018)].spring2018tospring2019.mean(), ndigits = 4))\n",
    "print(\"[\", round(df[(df.semester == \"spring\") & (df.year == 2018)].spring2018tospring2019.std(), ndigits = 4), \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between Spring 2018 and Fall 2018:  0.7655\n",
      "[ 0.0305 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Between Spring 2018 and Fall 2018: \", round(df[(df.semester == \"spring\") & (df.year == 2018)].spring2018tofall2018.mean(), ndigits = 4))\n",
    "print(\"[\", round(df[(df.semester == \"spring\") & (df.year == 2018)].spring2018tofall2018.std(), ndigits = 4), \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "      <th>term_freq</th>\n",
       "      <th>within_study</th>\n",
       "      <th>within_context</th>\n",
       "      <th>fall2018tospring2019</th>\n",
       "      <th>spring2018tospring2019</th>\n",
       "      <th>spring2018tofall2018</th>\n",
       "      <th>term_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2019_16_5C_TC Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:01] So, first thing is talk to ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[10, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.867354</td>\n",
       "      <td>0.832950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2019_89_5C_Transcript.docx</td>\n",
       "      <td>Coach: [00:00:00] How do you think the first s...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[12, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.848989</td>\n",
       "      <td>0.807627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2019_66_5C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:01] All right, so how do you th...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.810557</td>\n",
       "      <td>0.824666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8-2C.docx</td>\n",
       "      <td>[00:00:00] Coach: You can come over here and- ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "      <td>[9, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.834172</td>\n",
       "      <td>0.815356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787342</td>\n",
       "      <td>0.728036</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2019_65_5C_Transcript.docx</td>\n",
       "      <td>Coach: [00:00:08] All right. It’s hard. It’s h...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[15, 0, 0, 0, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>0.853230</td>\n",
       "      <td>0.841855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doc  \\\n",
       "142  2019_16_5C_TC Transcript.docx   \n",
       "137     2019_89_5C_Transcript.docx   \n",
       "126     2019_66_5C_Transcript.docx   \n",
       "82                       8-2C.docx   \n",
       "116     2019_65_5C_Transcript.docx   \n",
       "\n",
       "                                                  text  year semester  \\\n",
       "142  Coach:  [00:00:01] So, first thing is talk to ...  2019   spring   \n",
       "137  Coach: [00:00:00] How do you think the first s...  2019   spring   \n",
       "126  Coach:  [00:00:01] All right, so how do you th...  2019   spring   \n",
       "82   [00:00:00] Coach: You can come over here and- ...  2018   spring   \n",
       "116  Coach: [00:00:08] All right. It’s hard. It’s h...  2019   spring   \n",
       "\n",
       "                                             term_freq  within_study  \\\n",
       "142  [10, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.867354   \n",
       "137  [12, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.848989   \n",
       "126  [13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.810557   \n",
       "82   [9, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0.834172   \n",
       "116  [15, 0, 0, 0, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...      0.853230   \n",
       "\n",
       "     within_context  fall2018tospring2019  spring2018tospring2019  \\\n",
       "142        0.832950                   NaN                     NaN   \n",
       "137        0.807627                   NaN                     NaN   \n",
       "126        0.824666                   NaN                     NaN   \n",
       "82         0.815356                   NaN                0.787342   \n",
       "116        0.841855                   NaN                     NaN   \n",
       "\n",
       "     spring2018tofall2018                                        term_binary  \n",
       "142                   NaN  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "137                   NaN  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "126                   NaN  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "82               0.728036  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "116                   NaN  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_binary = []\n",
    "for row in df.term_freq:\n",
    "    new_row = []\n",
    "    for word in row:\n",
    "        if word > 0:\n",
    "            word = 1\n",
    "        new_row.append(word)\n",
    "    word_binary.append(new_row)\n",
    "df['term_binary'] = word_binary\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "      <th>term_freq</th>\n",
       "      <th>within_study</th>\n",
       "      <th>within_context</th>\n",
       "      <th>fall2018tospring2019</th>\n",
       "      <th>spring2018tospring2019</th>\n",
       "      <th>spring2018tofall2018</th>\n",
       "      <th>term_binary</th>\n",
       "      <th>within_study_jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>124-2C.docx</td>\n",
       "      <td>[00:00:00] Coach: So how do you feel? What do ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "      <td>[16, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.846081</td>\n",
       "      <td>0.832172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.732989</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.382194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>69-2C.docx</td>\n",
       "      <td>[00:00:00] Coach: Um, so how did you feel abou...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "      <td>[10, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.850511</td>\n",
       "      <td>0.852261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.854866</td>\n",
       "      <td>0.796663</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.383697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>7-2C.docx</td>\n",
       "      <td>[00:00:03] Coach: What do you mean? What's not...</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "      <td>[12, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.827612</td>\n",
       "      <td>0.816486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.799920</td>\n",
       "      <td>0.768371</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.375168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018_3_3C_Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:00] All right.  How did you thi...</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "      <td>[11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.796684</td>\n",
       "      <td>0.796684</td>\n",
       "      <td>0.710375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.334535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2019_16_5C_TC Transcript.docx</td>\n",
       "      <td>Coach:  [00:00:01] So, first thing is talk to ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>[10, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0.867354</td>\n",
       "      <td>0.832950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.373153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doc  \\\n",
       "54                     124-2C.docx   \n",
       "81                      69-2C.docx   \n",
       "59                       7-2C.docx   \n",
       "18       2018_3_3C_Transcript.docx   \n",
       "142  2019_16_5C_TC Transcript.docx   \n",
       "\n",
       "                                                  text  year semester  \\\n",
       "54   [00:00:00] Coach: So how do you feel? What do ...  2018   spring   \n",
       "81   [00:00:00] Coach: Um, so how did you feel abou...  2018   spring   \n",
       "59   [00:00:03] Coach: What do you mean? What's not...  2018   spring   \n",
       "18   Coach:  [00:00:00] All right.  How did you thi...  2018     fall   \n",
       "142  Coach:  [00:00:01] So, first thing is talk to ...  2019   spring   \n",
       "\n",
       "                                             term_freq  within_study  \\\n",
       "54   [16, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.846081   \n",
       "81   [10, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.850511   \n",
       "59   [12, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.827612   \n",
       "18   [11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.796684   \n",
       "142  [10, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0.867354   \n",
       "\n",
       "     within_context  fall2018tospring2019  spring2018tospring2019  \\\n",
       "54         0.832172                   NaN                0.811463   \n",
       "81         0.852261                   NaN                0.854866   \n",
       "59         0.816486                   NaN                0.799920   \n",
       "18         0.796684              0.710375                     NaN   \n",
       "142        0.832950                   NaN                     NaN   \n",
       "\n",
       "     spring2018tofall2018                                        term_binary  \\\n",
       "54               0.732989  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "81               0.796663  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "59               0.768371  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "18                    NaN  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "142                   NaN  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "     within_study_jaccard  \n",
       "54               0.382194  \n",
       "81               0.383697  \n",
       "59               0.375168  \n",
       "18               0.334535  \n",
       "142              0.373153  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['within_study_jaccard'] = np.nan\n",
    "def within_study_jaccard_mean(df, semester, year):\n",
    "    for maindoc in df[(df.semester == semester) & (df.year == year)].index:\n",
    "        jaccard_sim = []\n",
    "        for doc in df[(df.semester == semester) & (df.year == year)].index:\n",
    "            sim_vector = list(map(sum, zip(df.at[maindoc, 'term_binary'],df.at[doc, 'term_binary'])))\n",
    "            new_vector = []\n",
    "            for vect in sim_vector:\n",
    "                if vect == 2:\n",
    "                    new_vect = 1\n",
    "                if vect == 1:\n",
    "                    new_vect = 0\n",
    "                new_vector.append(new_vect)\n",
    "            sim_vector = new_vector\n",
    "            jaccard = sum(sim_vector)/len(sim_vector) \n",
    "            jaccard_sim.append(jaccard)\n",
    "        average = (sum(jaccard_sim) - 1)/(len(jaccard_sim) - 1) # don't include relationship with self\n",
    "        df.at[maindoc, 'within_study_jaccard'] = average\n",
    "    return df\n",
    "df = within_study_jaccard_mean(df, 'fall', 2018)\n",
    "df = within_study_jaccard_mean(df, 'spring', 2018)\n",
    "df = within_study_jaccard_mean(df, 'spring', 2019)\n",
    "\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Fall 2018:  0.383\n",
      "[ 0.0283 ]\n",
      "Within Spring 2018:  0.359\n",
      "[ 0.0188 ]\n",
      "Within Spring 2019:  0.37\n",
      "[ 0.0169 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Within Fall 2018: \", round(df[(df.semester == \"fall\") & (df.year == 2018)].within_study_jaccard.mean(), ndigits = 3))\n",
    "print(\"[\", round(df[(df.semester == \"fall\") & (df.year == 2018)].within_study_jaccard.std(), ndigits = 4), \"]\")\n",
    "print(\"Within Spring 2018: \", round(df[(df.semester == \"spring\") & (df.year == 2018)].within_study_jaccard.mean(), ndigits = 3))\n",
    "print(\"[\", round(df[(df.semester == \"spring\") & (df.year == 2018)].within_study_jaccard.std(), ndigits = 4), \"]\")\n",
    "print(\"Within Spring 2019: \", round(df[(df.semester == \"spring\") & (df.year == 2019)].within_study_jaccard.mean(), ndigits = 3))\n",
    "print(\"[\", round(df[(df.semester == \"spring\") & (df.year == 2019)].within_study_jaccard.std(), ndigits = 4), \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spacy]",
   "language": "python",
   "name": "conda-env-spacy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
