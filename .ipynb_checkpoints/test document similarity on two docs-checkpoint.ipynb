{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import operator\n",
    "\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50 for overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kylieleblancKylie/domino/docsim/data/Fall 2018/2. Feedback_Coaching/Feedback Coaching Transcripts/2018_118_3C_Transcript.docx\n"
     ]
    },
    {
     "ename": "PackageNotFoundError",
     "evalue": "Package not found at '/Users/kylieleblancKylie/domino/docsim/data/Fall 2018/2. Feedback_Coaching/Feedback Coaching Transcripts/2018_118_3C_Transcript.docx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-ba5a4d367613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdoc2_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc2_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdoc3_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/kylieleblancKylie/domino/docsim/data/Spring 2019/3. BR_Coaching/BR Coaching Transcripts/2019_2_5C_Transcript.docx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdoc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc1_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdoc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc2_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdoc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc3_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/spacy/lib/python3.7/site-packages/docx/api.py\u001b[0m in \u001b[0;36mDocument\u001b[0;34m(docx)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \"\"\"\n\u001b[1;32m     24\u001b[0m     \u001b[0mdocx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_docx_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdocx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdocx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdocument_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_document_part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdocument_part\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWML_DOCUMENT_MAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtmpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"file '%s' is not a Word file, content type is '%s'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/spacy/lib/python3.7/site-packages/docx/opc/package.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, pkg_file)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mpkg_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mpackage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mUnmarshaller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmarshal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPartFactory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/spacy/lib/python3.7/site-packages/docx/opc/pkgreader.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(pkg_file)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m|\u001b[0m\u001b[0mPackageReader\u001b[0m\u001b[0;34m|\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \"\"\"\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mphys_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhysPkgReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mcontent_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ContentTypeMap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_types_xml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mpkg_srels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_srels_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPACKAGE_URI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/spacy/lib/python3.7/site-packages/docx/opc/phys_pkg.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, pkg_file)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 raise PackageNotFoundError(\n\u001b[0;32m---> 31\u001b[0;31m                     \u001b[0;34m\"Package not found at '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpkg_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 )\n\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# assume it's a stream and pass it to Zip reader to sort out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPackageNotFoundError\u001b[0m: Package not found at '/Users/kylieleblancKylie/domino/docsim/data/Fall 2018/2. Feedback_Coaching/Feedback Coaching Transcripts/2018_118_3C_Transcript.docx'"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/kylieleblancKylie/domino/docsim/data/Fall 2018/2. Feedback_Coaching/Feedback Coaching Transcripts/'\n",
    "doc1_name = '2018_118_3C_Transcript.docx'\n",
    "doc2_name = '2018_115_3C_Transcript.docx'\n",
    "doc1_path = os.path.join(file_path, doc1_name)\n",
    "print(doc1_path)\n",
    "doc2_path = os.path.join(file_path, doc2_name)\n",
    "doc3_path = '/Users/kylieleblancKylie/domino/docsim/data/Spring 2019/3. BR_Coaching/BR Coaching Transcripts/2019_2_5C_Transcript.docx'\n",
    "doc1 = docx.Document(doc1_path)\n",
    "doc2 = docx.Document(doc2_path)\n",
    "doc3 = docx.Document(doc3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract text by coach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coach:  [00:00:00] So, how do you feel about that first simulation? [00:00:02]\\nCoach:  [00:00:06] So, hopefully we can get you feeling a little bit better about the next one, in this little bit of time we have.  So, first off, I would just like to say, I appreciated that you maintained enthusiasm.  I know that’s hard to do with the simulations and when you are interacting with avatars.  The next thing I want to point out, you, I was really impressed by the way that you were consistently probing them for the text-based evidence.  Every time the student were making a claim, you’re asking how do you know that?  Where can we find that in the text? That’s really great.  It helps provide us with some clarity and expands student thinking.  So, keep doing that in the next simulation because that was excellent.\\nCoach: [00:01:10] So when students aren’t understanding something, it’s really important for us to provide them with feedback that can support them in making sense of the text but then also in revising their answers. So, I just want thank you, I really appreciate the way that in question one, when Ethan made the statement that um, he thought that Lisa was excited.  You kind of redirected him and made him look at the text. [00:01:36]\\nCoach:  [00:01:38] And specifically the text with the lie detector results.  So that’s it. Can you think of another time during the simulation when a student said something, you know, that was possibly inaccurate? [00:01:48]\\nCoach:  [00:01:58] Good, okay. [00:01:59]\\nCoach:  [00:02:02] Okay, good.  So, question two, when you asked about who we think Lisa really is and Ava said that she thought that Lisa was a student intern. [00:02:13] \\nCoach:  [00:02:14] So, why was that not a valid claim? [00:02:15]\\nCoach:  [00:02:20] Right. So, we know that that’s just a cover.  So, in hindsight, what do you think that may be a better way to give Ava feedback, moving forward – you let Savannah go ahead and jump in, but how might you kind of, you know, follow this through with Ava?  What may be a way to give her feedback? [00:02:42]\\nCoach:  [00:02:56] Awesome, great.  So, you’re already doing really good with probing students to get text-based evidence, so you would just direct her back to this piece.  So if Pismo was so smart, would he be able to tell who she really was, would he know that her cover as a student intern was all a lie?  So you can have the student look at that piece of the text and then be like, Ava after re-reading this, do you still think that Lisa is just a student intern?  And hopefully she would change her response, right, as Ethan did – [00:03:23] \\nCoach:  [00:03:23] - in question one.  And then, just remember that every time a student changes their response, to give them that high quality descriptive feedback.  Be like, you know, Ava, I really liked the way that you went back, you spent time with the text, and then you were able to revise your answer, or just praise her because she comprehended the reading – [00:03:40]\\nCoach:  [00:03:42] - is something that really, you could say, that’s something that really good readers do, you know. [00:03:45]\\nCoach:  [00:03:46] So, um how might giving that kind of feedback, directing them back to the text be kind of preferable than moving on to maybe the next student’s response? [00:03:58]\\nCoach:  [00:04:18] Right.  So, clearly with Ava’s response, we can see with her claim that she may not fully – she’s not fully comprehending the text.  And we would just kind of move on and she may or may not get to a point where um she realizes that’s a misconception.  It also may lead the other students in the class, thinking, oh, maybe for question two, I could have student intern, spy or a reporter, right?  So, you want to make sure that you make it very clear that like, that’s – [00:04:45] \\nCoach:  [00:04:46] - not an acceptable option.  Okay, so let’s do like a really brief, actually we don’t have time to practice.  So, that’s okay, but did this all make sense?  Okay. [00:04:58]\\nCoach:  [00:04:59] Great. You’re gonna do great. [00:05:00]'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getCoachText(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        if len(para.text) > 5:\n",
    "            if para.text[0:6] == 'Coach:':\n",
    "                fullText.append(para.text)\n",
    "    return '\\n'.join(fullText)\n",
    "doc1_text = getCoachText(doc1_path)\n",
    "doc2_text = getCoachText(doc2_path)\n",
    "doc3_text = getCoachText(doc3_path)\n",
    "doc1_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize and drop stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopWords = set(nltk.corpus.stopwords.words('english'))\n",
    "stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '-',\n",
       " '-',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'able',\n",
       " 'able',\n",
       " 'acceptable',\n",
       " 'actually',\n",
       " 'ahead',\n",
       " 'already',\n",
       " 'also',\n",
       " 'also',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answer',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'ava',\n",
       " 'ava',\n",
       " 'ava',\n",
       " 'ava',\n",
       " 'ava',\n",
       " 'ava',\n",
       " 'avatar',\n",
       " 'awesome',\n",
       " 'back',\n",
       " 'back',\n",
       " 'back',\n",
       " 'better',\n",
       " 'better',\n",
       " 'bit',\n",
       " 'bit',\n",
       " 'brief',\n",
       " 'change',\n",
       " 'change',\n",
       " 'claim',\n",
       " 'claim',\n",
       " 'claim',\n",
       " 'clarity',\n",
       " 'class',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'coach',\n",
       " 'comprehended',\n",
       " 'comprehending',\n",
       " 'consistently',\n",
       " 'could',\n",
       " 'could',\n",
       " 'cover',\n",
       " 'cover',\n",
       " 'descriptive',\n",
       " 'detector',\n",
       " 'direct',\n",
       " 'directing',\n",
       " 'enthusiasm',\n",
       " 'ethan',\n",
       " 'ethan',\n",
       " 'every',\n",
       " 'every',\n",
       " 'evidence',\n",
       " 'evidence',\n",
       " 'excellent',\n",
       " 'excited',\n",
       " 'expands',\n",
       " 'feedback',\n",
       " 'feedback',\n",
       " 'feedback',\n",
       " 'feedback',\n",
       " 'feedback',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'find',\n",
       " 'first',\n",
       " 'first',\n",
       " 'follow',\n",
       " 'forward',\n",
       " 'fully',\n",
       " 'fully',\n",
       " 'get',\n",
       " 'get',\n",
       " 'get',\n",
       " 'give',\n",
       " 'give',\n",
       " 'give',\n",
       " 'giving',\n",
       " 'go',\n",
       " 'gon',\n",
       " 'good',\n",
       " 'good',\n",
       " 'good',\n",
       " 'good',\n",
       " 'great',\n",
       " 'great',\n",
       " 'great',\n",
       " 'great',\n",
       " 'hard',\n",
       " 'help',\n",
       " 'high',\n",
       " 'hindsight',\n",
       " 'hopefully',\n",
       " 'hopefully',\n",
       " 'important',\n",
       " 'impressed',\n",
       " 'inaccurate',\n",
       " 'interacting',\n",
       " 'intern',\n",
       " 'intern',\n",
       " 'intern',\n",
       " 'intern',\n",
       " 'jump',\n",
       " 'keep',\n",
       " 'kind',\n",
       " 'kind',\n",
       " 'kind',\n",
       " 'kind',\n",
       " 'kind',\n",
       " 'know',\n",
       " 'know',\n",
       " 'know',\n",
       " 'know',\n",
       " 'know',\n",
       " 'know',\n",
       " 'know',\n",
       " 'know',\n",
       " 'lead',\n",
       " 'let',\n",
       " 'let',\n",
       " 'lie',\n",
       " 'lie',\n",
       " 'like',\n",
       " 'like',\n",
       " 'like',\n",
       " 'like',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'lisa',\n",
       " 'lisa',\n",
       " 'lisa',\n",
       " 'lisa',\n",
       " 'little',\n",
       " 'little',\n",
       " 'look',\n",
       " 'look',\n",
       " 'made',\n",
       " 'made',\n",
       " 'maintained',\n",
       " 'make',\n",
       " 'make',\n",
       " 'make',\n",
       " 'making',\n",
       " 'making',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'maybe',\n",
       " 'might',\n",
       " 'might',\n",
       " 'misconception',\n",
       " 'move',\n",
       " 'moving',\n",
       " 'moving',\n",
       " 'na',\n",
       " 'next',\n",
       " 'next',\n",
       " 'next',\n",
       " 'next',\n",
       " 'oh',\n",
       " 'okay',\n",
       " 'okay',\n",
       " 'okay',\n",
       " 'okay',\n",
       " 'okay',\n",
       " 'one',\n",
       " 'one',\n",
       " 'one',\n",
       " 'option',\n",
       " 'piece',\n",
       " 'piece',\n",
       " 'pismo',\n",
       " 'point',\n",
       " 'point',\n",
       " 'possibly',\n",
       " 'practice',\n",
       " 'praise',\n",
       " 'preferable',\n",
       " 'probing',\n",
       " 'probing',\n",
       " 'provide',\n",
       " 'provide',\n",
       " 'quality',\n",
       " 'question',\n",
       " 'question',\n",
       " 'question',\n",
       " 'question',\n",
       " 're-reading',\n",
       " 'reader',\n",
       " 'reading',\n",
       " 'realizes',\n",
       " 'really',\n",
       " 'really',\n",
       " 'really',\n",
       " 'really',\n",
       " 'really',\n",
       " 'really',\n",
       " 'really',\n",
       " 'really',\n",
       " 'really',\n",
       " 'really',\n",
       " 'really',\n",
       " 'redirected',\n",
       " 'remember',\n",
       " 'reporter',\n",
       " 'response',\n",
       " 'response',\n",
       " 'response',\n",
       " 'response',\n",
       " 'result',\n",
       " 'revise',\n",
       " 'revising',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'right',\n",
       " 'said',\n",
       " 'said',\n",
       " 'savannah',\n",
       " 'say',\n",
       " 'say',\n",
       " 'see',\n",
       " 'sense',\n",
       " 'sense',\n",
       " 'simulation',\n",
       " 'simulation',\n",
       " 'simulation',\n",
       " 'simulation',\n",
       " 'smart',\n",
       " 'something',\n",
       " 'something',\n",
       " 'something',\n",
       " 'something',\n",
       " 'specifically',\n",
       " 'spent',\n",
       " 'spy',\n",
       " 'statement',\n",
       " 'still',\n",
       " 'student',\n",
       " 'student',\n",
       " 'student',\n",
       " 'student',\n",
       " 'student',\n",
       " 'student',\n",
       " 'student',\n",
       " 'student',\n",
       " 'student',\n",
       " 'student',\n",
       " 'student',\n",
       " 'student',\n",
       " 'student',\n",
       " 'support',\n",
       " 'sure',\n",
       " 'tell',\n",
       " 'text',\n",
       " 'text',\n",
       " 'text',\n",
       " 'text',\n",
       " 'text',\n",
       " 'text',\n",
       " 'text',\n",
       " 'text',\n",
       " 'text-based',\n",
       " 'text-based',\n",
       " 'thank',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'think',\n",
       " 'think',\n",
       " 'think',\n",
       " 'thinking',\n",
       " 'thinking',\n",
       " 'thought',\n",
       " 'thought',\n",
       " 'time',\n",
       " 'time',\n",
       " 'time',\n",
       " 'time',\n",
       " 'time',\n",
       " 'time',\n",
       " 'two',\n",
       " 'two',\n",
       " 'u',\n",
       " 'u',\n",
       " 'um',\n",
       " 'um',\n",
       " 'um',\n",
       " 'understanding',\n",
       " 'valid',\n",
       " 'want',\n",
       " 'want',\n",
       " 'want',\n",
       " 'way',\n",
       " 'way',\n",
       " 'way',\n",
       " 'way',\n",
       " 'way',\n",
       " 'went',\n",
       " 'would',\n",
       " 'would',\n",
       " 'would',\n",
       " 'would',\n",
       " 'would',\n",
       " 'would',\n",
       " '–',\n",
       " '–',\n",
       " '–',\n",
       " '–',\n",
       " '–',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’',\n",
       " '’']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_nostop(doc):\n",
    "    words = word_tokenize(doc)\n",
    "    wordsFiltered = []\n",
    "\n",
    "    for w in words:\n",
    "        #drop coach? drop time stamp? drop punctuation? add back stop words?\n",
    "        w = w.lower()\n",
    "        if w not in stopWords and w not in ['[', '.', ']', ':', ',', '\"', '00', '24', ','] and not w.startswith('00:'): #drop coach? drop time stamp? drop punctuation? add back stop words?\n",
    "            w = lemmatizer.lemmatize(w) # improve with POS tag\n",
    "            wordsFiltered.append(w)\n",
    "    return wordsFiltered\n",
    "\n",
    "doc1_words = tokenize_nostop(doc1_text)\n",
    "doc2_words = tokenize_nostop(doc2_text)\n",
    "doc3_words = tokenize_nostop(doc3_text)\n",
    "sorted(doc1_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard Similarity\n",
    "## words in common/all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "between Fall sessions:  0.3641025641025641\n",
      "between one fall and one spring:  0.21785714285714286\n"
     ]
    }
   ],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1) \n",
    "    b = set(str2)\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "print('between Fall sessions: ', get_jaccard_sim(doc1_words, doc2_words))\n",
    "print('between one fall and one spring: ', get_jaccard_sim(doc1_words, doc3_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity\n",
    "## takes word frequency into account\n",
    "### Cosine similarity measures the cosine of angle between two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('able', 0),\n",
       " ('acceptable', 1),\n",
       " ('actually', 2),\n",
       " ('ahead', 3),\n",
       " ('already', 4),\n",
       " ('also', 5),\n",
       " ('another', 6),\n",
       " ('answer', 7),\n",
       " ('appreciate', 8),\n",
       " ('appreciated', 9),\n",
       " ('asked', 10),\n",
       " ('asking', 11),\n",
       " ('ava', 12),\n",
       " ('avatar', 13),\n",
       " ('awesome', 14),\n",
       " ('back', 15),\n",
       " ('based', 16),\n",
       " ('better', 17),\n",
       " ('bit', 18),\n",
       " ('brief', 19),\n",
       " ('change', 20),\n",
       " ('claim', 21),\n",
       " ('clarity', 22),\n",
       " ('class', 23),\n",
       " ('clear', 24),\n",
       " ('clearly', 25),\n",
       " ('coach', 26),\n",
       " ('comprehended', 27),\n",
       " ('comprehending', 28),\n",
       " ('consistently', 29),\n",
       " ('could', 30),\n",
       " ('cover', 31),\n",
       " ('descriptive', 32),\n",
       " ('detector', 33),\n",
       " ('direct', 34),\n",
       " ('directing', 35),\n",
       " ('enthusiasm', 36),\n",
       " ('ethan', 37),\n",
       " ('every', 38),\n",
       " ('evidence', 39),\n",
       " ('excellent', 40),\n",
       " ('excited', 41),\n",
       " ('expands', 42),\n",
       " ('feedback', 43),\n",
       " ('feel', 44),\n",
       " ('feeling', 45),\n",
       " ('find', 46),\n",
       " ('first', 47),\n",
       " ('follow', 48),\n",
       " ('forward', 49),\n",
       " ('fully', 50),\n",
       " ('get', 51),\n",
       " ('give', 52),\n",
       " ('giving', 53),\n",
       " ('go', 54),\n",
       " ('gon', 55),\n",
       " ('good', 56),\n",
       " ('great', 57),\n",
       " ('hard', 58),\n",
       " ('help', 59),\n",
       " ('high', 60),\n",
       " ('hindsight', 61),\n",
       " ('hopefully', 62),\n",
       " ('important', 63),\n",
       " ('impressed', 64),\n",
       " ('inaccurate', 65),\n",
       " ('interacting', 66),\n",
       " ('intern', 67),\n",
       " ('jump', 68),\n",
       " ('keep', 69),\n",
       " ('kind', 70),\n",
       " ('know', 71),\n",
       " ('lead', 72),\n",
       " ('let', 73),\n",
       " ('lie', 74),\n",
       " ('like', 75),\n",
       " ('liked', 76),\n",
       " ('lisa', 77),\n",
       " ('little', 78),\n",
       " ('look', 79),\n",
       " ('made', 80),\n",
       " ('maintained', 81),\n",
       " ('make', 82),\n",
       " ('making', 83),\n",
       " ('may', 84),\n",
       " ('maybe', 85),\n",
       " ('might', 86),\n",
       " ('misconception', 87),\n",
       " ('move', 88),\n",
       " ('moving', 89),\n",
       " ('na', 90),\n",
       " ('next', 91),\n",
       " ('oh', 92),\n",
       " ('okay', 93),\n",
       " ('one', 94),\n",
       " ('option', 95),\n",
       " ('piece', 96),\n",
       " ('pismo', 97),\n",
       " ('point', 98),\n",
       " ('possibly', 99),\n",
       " ('practice', 100),\n",
       " ('praise', 101),\n",
       " ('preferable', 102),\n",
       " ('probing', 103),\n",
       " ('provide', 104),\n",
       " ('quality', 105),\n",
       " ('question', 106),\n",
       " ('re', 107),\n",
       " ('reader', 108),\n",
       " ('reading', 109),\n",
       " ('realizes', 110),\n",
       " ('really', 111),\n",
       " ('redirected', 112),\n",
       " ('remember', 113),\n",
       " ('reporter', 114),\n",
       " ('response', 115),\n",
       " ('result', 116),\n",
       " ('revise', 117),\n",
       " ('revising', 118),\n",
       " ('right', 119),\n",
       " ('said', 120),\n",
       " ('savannah', 121),\n",
       " ('say', 122),\n",
       " ('see', 123),\n",
       " ('sense', 124),\n",
       " ('simulation', 125),\n",
       " ('smart', 126),\n",
       " ('something', 127),\n",
       " ('specifically', 128),\n",
       " ('spent', 129),\n",
       " ('spy', 130),\n",
       " ('statement', 131),\n",
       " ('still', 132),\n",
       " ('student', 133),\n",
       " ('support', 134),\n",
       " ('sure', 135),\n",
       " ('tell', 136),\n",
       " ('text', 137),\n",
       " ('thank', 138),\n",
       " ('thing', 139),\n",
       " ('think', 140),\n",
       " ('thinking', 141),\n",
       " ('thought', 142),\n",
       " ('time', 143),\n",
       " ('two', 144),\n",
       " ('um', 145),\n",
       " ('understanding', 146),\n",
       " ('valid', 147),\n",
       " ('want', 148),\n",
       " ('way', 149),\n",
       " ('went', 150),\n",
       " ('would', 151)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "text = [t for t in doc1_words]\n",
    "vectorizer.fit(text)\n",
    "sorted_vocab = sorted(vectorizer.vocabulary_.items(), key=operator.itemgetter(1))\n",
    "sorted_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "between fall sessions:  0.6813979997963618\n",
      "between one fall and one spring:  0.5484839092171141\n"
     ]
    }
   ],
   "source": [
    "doc1_text_stopwords_removed = ' '.join(doc1_words)\n",
    "doc2_text_stopwords_removed = ' '.join(doc2_words)\n",
    "doc3_text_stopwords_removed = ' '.join(doc3_words)\n",
    "\n",
    "\n",
    "\n",
    "def get_cosine_sim(*strs): \n",
    "    vectors = [t for t in get_vectors(*strs)]\n",
    "    return cosine_similarity(vectors)\n",
    "    \n",
    "def get_vectors(*strs):\n",
    "    text = [t for t in strs]\n",
    "    vectorizer.fit(text)\n",
    "    #print(sorted(vectorizer.vocabulary_.items(), key=operator.itemgetter(1)))\n",
    "    #print(vectorizer.transform(text).toarray())\n",
    "    return vectorizer.transform(text).toarray()\n",
    "print('between fall sessions: ', get_cosine_sim(doc1_text_stopwords_removed, doc2_text_stopwords_removed)[0][1])\n",
    "print('between one fall and one spring: ', get_cosine_sim(doc1_text_stopwords_removed, doc3_text_stopwords_removed)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity with tf-idf\n",
    "#### weights unique words from doc higher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coach': 30, 'feel': 54, 'first': 57, 'simulation': 153, 'hopefully': 75, 'get': 61, 'feeling': 55, 'little': 93, 'bit': 22, 'better': 21, 'next': 109, 'one': 112, 'time': 174, 'would': 184, 'like': 89, 'say': 146, 'appreciated': 12, 'maintained': 96, 'enthusiasm': 44, 'know': 85, 'hard': 71, 'interacting': 80, 'avatar': 16, 'thing': 170, 'want': 180, 'point': 116, 'really': 134, 'impressed': 77, 'way': 181, 'consistently': 35, 'probing': 124, 'text': 168, 'based': 19, 'evidence': 48, 'every': 47, 'student': 162, 'making': 99, 'claim': 25, 'asking': 14, 'find': 56, 'great': 69, 'help': 72, 'provide': 125, 'clarity': 26, 'expands': 51, 'thinking': 172, 'keep': 83, 'excellent': 49, 'understanding': 178, 'something': 156, 'important': 76, 'feedback': 53, 'support': 164, 'sense': 152, 'also': 8, 'revising': 141, 'answer': 10, 'thank': 169, 'appreciate': 11, 'question': 129, 'ethan': 45, 'made': 95, 'statement': 160, 'um': 177, 'thought': 173, 'lisa': 92, 'excited': 50, 'kind': 84, 'redirected': 135, 'look': 94, 'specifically': 157, 'lie': 88, 'detector': 40, 'result': 139, 'think': 171, 'another': 9, 'said': 144, 'possibly': 118, 'inaccurate': 78, 'good': 68, 'okay': 111, 'two': 175, 'asked': 13, 'ava': 15, 'intern': 81, 'valid': 179, 'right': 143, 'cover': 38, 'hindsight': 74, 'may': 100, 'give': 62, 'moving': 107, 'forward': 59, 'let': 87, 'savannah': 145, 'go': 66, 'ahead': 6, 'jump': 82, 'might': 103, 'follow': 58, 'awesome': 17, 'already': 7, 'direct': 41, 'back': 18, 'piece': 114, 'pismo': 115, 'smart': 155, 'able': 2, 'tell': 167, 're': 130, 'reading': 132, 'still': 161, 'change': 24, 'response': 138, 'remember': 136, 'high': 73, 'quality': 128, 'descriptive': 39, 'liked': 90, 'went': 183, 'spent': 158, 'revise': 140, 'praise': 120, 'comprehended': 32, 'could': 37, 'reader': 131, 'giving': 64, 'directing': 42, 'preferable': 121, 'maybe': 101, 'clearly': 29, 'see': 151, 'fully': 60, 'comprehending': 33, 'move': 106, 'realizes': 133, 'misconception': 104, 'lead': 86, 'class': 27, 'oh': 110, 'spy': 159, 'reporter': 137, 'make': 98, 'sure': 165, 'clear': 28, 'acceptable': 3, 'option': 113, 'brief': 23, 'actually': 4, 'practice': 119, 'gon': 67, 'na': 108, '00': 0, '24': 1, 'glad': 65, 'even': 46, 'prepared': 122, 'comment': 31, 'maintaining': 97, 'second': 150, 'pointed': 117, 'constantly': 36, 'explanation': 52, 'advantageous': 5, 'moment': 105, 'scaffolding': 149, 'comprehension': 34, 'well': 182, 'putting': 127, 'behavior': 20, 'instance': 79, 'revived': 142, 'saying': 147, 'talk': 166, 'type': 176, 'providing': 126, 'summary': 163, 'mean': 102, 'given': 63, 'limited': 91, 'skipped': 154, 'probed': 123, 'scaffolded': 148, 'guess': 70, 'else': 43}\n",
      "[[0.         0.         0.06861107 0.02440867 0.03430553 0.\n",
      "  0.03430553 0.03430553 0.06861107 0.03430553 0.04881734 0.03430553\n",
      "  0.03430553 0.03430553 0.03430553 0.14645202 0.02440867 0.02440867\n",
      "  0.07322601 0.04881734 0.         0.06861107 0.04881734 0.03430553\n",
      "  0.04881734 0.07322601 0.03430553 0.03430553 0.03430553 0.03430553\n",
      "  0.36613005 0.         0.03430553 0.03430553 0.         0.03430553\n",
      "  0.         0.06861107 0.06861107 0.02440867 0.03430553 0.03430553\n",
      "  0.03430553 0.         0.02440867 0.04881734 0.         0.06861107\n",
      "  0.04881734 0.03430553 0.02440867 0.03430553 0.         0.12204335\n",
      "  0.02440867 0.02440867 0.02440867 0.04881734 0.03430553 0.02440867\n",
      "  0.06861107 0.1029166  0.07322601 0.         0.02440867 0.\n",
      "  0.02440867 0.03430553 0.09763468 0.09763468 0.         0.02440867\n",
      "  0.03430553 0.02440867 0.03430553 0.04881734 0.03430553 0.03430553\n",
      "  0.03430553 0.         0.02440867 0.13722213 0.03430553 0.02440867\n",
      "  0.12204335 0.19526936 0.03430553 0.04881734 0.06861107 0.12204335\n",
      "  0.03430553 0.         0.13722213 0.04881734 0.06861107 0.06861107\n",
      "  0.03430553 0.         0.07322601 0.06861107 0.2058332  0.06861107\n",
      "  0.         0.04881734 0.03430553 0.         0.03430553 0.04881734\n",
      "  0.03430553 0.09763468 0.03430553 0.12204335 0.07322601 0.03430553\n",
      "  0.06861107 0.03430553 0.06861107 0.         0.03430553 0.03430553\n",
      "  0.03430553 0.02440867 0.         0.         0.04881734 0.04881734\n",
      "  0.         0.         0.02440867 0.09763468 0.02440867 0.03430553\n",
      "  0.06861107 0.03430553 0.26849537 0.03430553 0.03430553 0.03430553\n",
      "  0.09763468 0.03430553 0.03430553 0.03430553 0.         0.13722213\n",
      "  0.04881734 0.02440867 0.04881734 0.         0.         0.\n",
      "  0.         0.02440867 0.06861107 0.13722213 0.         0.03430553\n",
      "  0.09763468 0.03430553 0.03430553 0.03430553 0.03430553 0.03430553\n",
      "  0.31731271 0.         0.02440867 0.02440867 0.         0.03430553\n",
      "  0.2440867  0.03430553 0.02440867 0.09763468 0.06861107 0.06861107\n",
      "  0.14645202 0.04881734 0.         0.07322601 0.03430553 0.03430553\n",
      "  0.07322601 0.17152767 0.         0.02440867 0.14645202]\n",
      " [0.17145042 0.05715014 0.         0.0406628  0.         0.05715014\n",
      "  0.         0.         0.         0.         0.08132559 0.\n",
      "  0.         0.         0.         0.12198839 0.0406628  0.0406628\n",
      "  0.16265119 0.0406628  0.05715014 0.         0.08132559 0.\n",
      "  0.08132559 0.0406628  0.         0.         0.         0.\n",
      "  0.44729076 0.05715014 0.         0.         0.05715014 0.\n",
      "  0.05715014 0.         0.         0.0406628  0.         0.\n",
      "  0.         0.05715014 0.0406628  0.0406628  0.05715014 0.\n",
      "  0.0406628  0.         0.0406628  0.         0.05715014 0.12198839\n",
      "  0.0406628  0.0406628  0.0406628  0.0406628  0.         0.0406628\n",
      "  0.         0.         0.0406628  0.05715014 0.0406628  0.05715014\n",
      "  0.08132559 0.         0.12198839 0.0406628  0.05715014 0.0406628\n",
      "  0.         0.0406628  0.         0.0406628  0.         0.\n",
      "  0.         0.05715014 0.0406628  0.         0.         0.0406628\n",
      "  0.12198839 0.12198839 0.         0.12198839 0.         0.40662796\n",
      "  0.         0.05715014 0.         0.08132559 0.         0.\n",
      "  0.         0.05715014 0.12198839 0.         0.         0.\n",
      "  0.05715014 0.20331398 0.         0.05715014 0.         0.08132559\n",
      "  0.         0.0406628  0.         0.20331398 0.0406628  0.\n",
      "  0.         0.         0.         0.05715014 0.         0.\n",
      "  0.         0.0406628  0.05715014 0.05715014 0.0406628  0.0406628\n",
      "  0.05715014 0.05715014 0.0406628  0.0406628  0.08132559 0.\n",
      "  0.         0.         0.08132559 0.         0.         0.\n",
      "  0.0406628  0.         0.         0.         0.05715014 0.\n",
      "  0.0406628  0.0406628  0.08132559 0.05715014 0.05715014 0.05715014\n",
      "  0.05715014 0.0406628  0.         0.         0.05715014 0.\n",
      "  0.08132559 0.         0.         0.         0.         0.\n",
      "  0.0406628  0.05715014 0.0406628  0.0406628  0.05715014 0.\n",
      "  0.12198839 0.         0.08132559 0.20331398 0.         0.\n",
      "  0.16265119 0.08132559 0.05715014 0.12198839 0.         0.\n",
      "  0.0406628  0.         0.17145042 0.08132559 0.12198839]]\n",
      "{'coach': 40, 'feel': 74, 'first': 77, 'simulation': 210, 'hopefully': 105, 'get': 85, 'feeling': 75, 'little': 129, 'bit': 26, 'better': 25, 'next': 149, 'one': 154, 'time': 244, 'would': 265, 'like': 126, 'say': 203, 'appreciated': 10, 'maintained': 135, 'enthusiasm': 63, 'know': 119, 'hard': 99, 'interacting': 112, 'avatar': 16, 'thing': 238, 'want': 257, 'point': 162, 'really': 186, 'impressed': 108, 'way': 258, 'consistently': 44, 'probing': 170, 'text': 236, 'based': 22, 'evidence': 68, 'every': 67, 'student': 225, 'making': 137, 'claim': 34, 'asking': 12, 'find': 76, 'great': 95, 'help': 100, 'provide': 171, 'clarity': 36, 'expands': 72, 'thinking': 240, 'keep': 115, 'excellent': 70, 'understanding': 251, 'something': 212, 'important': 107, 'feedback': 73, 'support': 228, 'sense': 208, 'also': 6, 'revising': 198, 'answer': 8, 'thank': 237, 'appreciate': 9, 'question': 175, 'ethan': 65, 'made': 133, 'statement': 220, 'um': 249, 'thought': 241, 'lisa': 128, 'excited': 71, 'kind': 117, 'redirected': 189, 'look': 130, 'specifically': 215, 'lie': 125, 'detector': 53, 'result': 196, 'think': 239, 'another': 7, 'said': 200, 'possibly': 164, 'inaccurate': 109, 'good': 93, 'okay': 153, 'two': 248, 'asked': 11, 'ava': 15, 'intern': 113, 'valid': 253, 'right': 199, 'cover': 50, 'hindsight': 104, 'may': 138, 'give': 87, 'moving': 145, 'forward': 80, 'let': 123, 'savannah': 202, 'go': 90, 'ahead': 4, 'jump': 114, 'might': 140, 'follow': 79, 'awesome': 19, 'already': 5, 'direct': 55, 'back': 20, 'piece': 159, 'pismo': 160, 'smart': 211, 'able': 0, 'tell': 234, 're': 180, 'reading': 182, 'still': 221, 'change': 33, 'response': 195, 'remember': 192, 'high': 103, 'quality': 174, 'descriptive': 52, 'liked': 127, 'went': 259, 'spent': 216, 'revise': 197, 'praise': 166, 'comprehended': 42, 'could': 47, 'reader': 181, 'giving': 89, 'directing': 56, 'preferable': 167, 'maybe': 139, 'clearly': 39, 'see': 206, 'fully': 82, 'comprehending': 43, 'move': 144, 'realizes': 185, 'misconception': 143, 'lead': 121, 'class': 37, 'oh': 152, 'spy': 217, 'reporter': 193, 'make': 136, 'sure': 229, 'clear': 38, 'acceptable': 1, 'option': 155, 'brief': 28, 'actually': 3, 'practice': 165, 'gon': 92, 'na': 147, 'work': 263, 'couple': 48, 'started': 218, 'maintain': 134, 'pushing': 173, 'grinding': 96, 'throwing': 243, 'lot': 131, 'much': 146, 'students': 226, 'of': 151, 'course': 49, 'dev': 54, 'were': 260, 'engaging': 62, 'misbehavior': 141, 'immediately': 106, 'acknowledging': 2, 'recognizing': 187, 'lens': 122, 'seeing': 207, 'starting': 219, 'quite': 178, 'throughout': 242, 'past': 157, 'stimulation': 222, 'various': 254, 'specific': 214, 'instruction': 111, 'attempt': 13, 'redirect': 188, 'instance': 110, 'beat': 23, 'boxing': 27, 'period': 158, 'please': 161, 'quiet': 177, 'stopped': 224, 'helpful': 101, 'sake': 201, 'getting': 86, 'prepared': 168, 'continue': 45, 'emphasize': 60, 'redirections': 190, 'possible': 163, 'term': 235, 'behavior': 24, 'discontinue': 57, 'succinct': 227, 'last': 120, 'example': 69, 'take': 231, 'trying': 247, 'engage': 61, 'conversation': 46, 'try': 246, 'talking': 233, 'respect': 194, 'happened': 98, 'gave': 83, 'shorten': 209, 'why': 261, 'front': 81, 'understand': 250, 'coming': 41, 'given': 88, 'day': 51, 'build': 30, 'rapport': 179, 'establish': 64, 'relationship': 191, 'miscommunication': 142, 'stop': 223, 'hey': 102, 'attention': 14, 'focused': 78, 'yeah': 266, 'aware': 17, 'letting': 124, 'scaffolding': 205, 'or': 156, 'wan': 256, 'use': 252, 'word': 262, 'low': 132, 'grade': 94, 'working': 264, 'taking': 232, 'away': 18, 'distracting': 58, 'soon': 213, 'caution': 32, 'real': 184, 'kid': 116, 'going': 91, 'push': 172, 'quick': 176, 'name': 148, 'cassidy': 31, 'pretend': 169, 'bring': 29, 'ready': 183, 'drum': 59, 'table': 230, 'bad': 21, 'saying': 204, 'even': 66, 'non': 150, 'verbal': 255, 'gesture': 84, 'kinda': 118, 'clap': 35, 'hand': 97, 'together': 245}\n",
      "[[0.04630266 0.03253839 0.         0.03253839 0.03253839 0.02315133\n",
      "  0.04630266 0.02315133 0.06507678 0.02315133 0.03253839 0.03253839\n",
      "  0.03253839 0.         0.         0.19523033 0.03253839 0.\n",
      "  0.         0.03253839 0.06945399 0.         0.06507678 0.\n",
      "  0.         0.04630266 0.04630266 0.         0.02315133 0.\n",
      "  0.         0.         0.         0.06507678 0.09761517 0.\n",
      "  0.03253839 0.02315133 0.02315133 0.03253839 0.34726997 0.\n",
      "  0.03253839 0.03253839 0.03253839 0.         0.         0.04630266\n",
      "  0.         0.         0.06507678 0.         0.03253839 0.03253839\n",
      "  0.         0.03253839 0.03253839 0.         0.         0.\n",
      "  0.         0.         0.         0.02315133 0.         0.04630266\n",
      "  0.         0.04630266 0.06507678 0.         0.03253839 0.03253839\n",
      "  0.03253839 0.16269194 0.02315133 0.02315133 0.03253839 0.04630266\n",
      "  0.         0.03253839 0.03253839 0.         0.06507678 0.\n",
      "  0.         0.06945399 0.         0.09761517 0.         0.02315133\n",
      "  0.02315133 0.         0.03253839 0.09260533 0.         0.09260533\n",
      "  0.         0.         0.         0.02315133 0.03253839 0.\n",
      "  0.         0.03253839 0.03253839 0.04630266 0.         0.02315133\n",
      "  0.03253839 0.03253839 0.         0.         0.03253839 0.13015355\n",
      "  0.03253839 0.02315133 0.         0.11575666 0.         0.18521065\n",
      "  0.         0.03253839 0.         0.06507678 0.         0.06507678\n",
      "  0.11575666 0.03253839 0.13015355 0.04630266 0.06507678 0.\n",
      "  0.         0.06507678 0.         0.03253839 0.06945399 0.04630266\n",
      "  0.19523033 0.06507678 0.04630266 0.         0.         0.03253839\n",
      "  0.03253839 0.06507678 0.         0.02315133 0.         0.09260533\n",
      "  0.         0.         0.03253839 0.11575666 0.06945399 0.02315133\n",
      "  0.         0.         0.         0.06507678 0.03253839 0.\n",
      "  0.04630266 0.         0.03253839 0.02315133 0.03253839 0.03253839\n",
      "  0.         0.         0.06507678 0.04630266 0.         0.\n",
      "  0.03253839 0.13015355 0.         0.         0.         0.\n",
      "  0.02315133 0.03253839 0.06507678 0.         0.         0.03253839\n",
      "  0.25466465 0.         0.         0.03253839 0.         0.\n",
      "  0.02315133 0.03253839 0.         0.13015355 0.03253839 0.03253839\n",
      "  0.03253839 0.09260533 0.04630266 0.         0.03253839 0.04630266\n",
      "  0.         0.         0.02315133 0.         0.06507678 0.\n",
      "  0.09260533 0.03253839 0.13015355 0.         0.         0.03253839\n",
      "  0.03253839 0.03253839 0.         0.         0.03253839 0.03253839\n",
      "  0.         0.         0.         0.30096731 0.         0.\n",
      "  0.03253839 0.02315133 0.         0.         0.         0.\n",
      "  0.02315133 0.         0.32538389 0.03253839 0.02315133 0.09260533\n",
      "  0.06507678 0.06507678 0.         0.         0.13890799 0.\n",
      "  0.         0.         0.06507678 0.06945399 0.         0.03253839\n",
      "  0.         0.03253839 0.         0.         0.         0.06945399\n",
      "  0.16269194 0.03253839 0.         0.         0.         0.\n",
      "  0.         0.13890799 0.        ]\n",
      " [0.02414972 0.         0.03394159 0.         0.         0.02414972\n",
      "  0.07244917 0.04829945 0.         0.04829945 0.         0.\n",
      "  0.         0.03394159 0.03394159 0.         0.         0.06788318\n",
      "  0.06788318 0.         0.02414972 0.03394159 0.         0.03394159\n",
      "  0.13576637 0.04829945 0.02414972 0.03394159 0.02414972 0.03394159\n",
      "  0.03394159 0.13576637 0.03394159 0.         0.         0.03394159\n",
      "  0.         0.02414972 0.02414972 0.         0.36224584 0.03394159\n",
      "  0.         0.         0.         0.03394159 0.06788318 0.04829945\n",
      "  0.03394159 0.03394159 0.         0.03394159 0.         0.\n",
      "  0.03394159 0.         0.         0.03394159 0.03394159 0.03394159\n",
      "  0.03394159 0.06788318 0.03394159 0.02414972 0.03394159 0.12074861\n",
      "  0.03394159 0.02414972 0.         0.03394159 0.         0.\n",
      "  0.         0.         0.04829945 0.02414972 0.         0.07244917\n",
      "  0.10182478 0.         0.         0.03394159 0.         0.03394159\n",
      "  0.03394159 0.12074861 0.03394159 0.         0.03394159 0.02414972\n",
      "  0.02414972 0.06788318 0.         0.02414972 0.03394159 0.02414972\n",
      "  0.03394159 0.03394159 0.03394159 0.02414972 0.         0.03394159\n",
      "  0.03394159 0.         0.         0.04829945 0.03394159 0.02414972\n",
      "  0.         0.         0.03394159 0.06788318 0.         0.\n",
      "  0.         0.04829945 0.03394159 0.12074861 0.03394159 0.12074861\n",
      "  0.03394159 0.         0.03394159 0.         0.03394159 0.\n",
      "  0.31394639 0.         0.         0.04829945 0.         0.16970796\n",
      "  0.03394159 0.         0.03394159 0.         0.02414972 0.04829945\n",
      "  0.         0.         0.02414972 0.13576637 0.06788318 0.\n",
      "  0.         0.         0.06788318 0.02414972 0.03394159 0.04829945\n",
      "  0.03394159 0.03394159 0.         0.07244917 0.12074861 0.02414972\n",
      "  0.03394159 0.03394159 0.03394159 0.         0.         0.16970796\n",
      "  0.04829945 0.13576637 0.         0.04829945 0.         0.\n",
      "  0.03394159 0.03394159 0.         0.02414972 0.03394159 0.03394159\n",
      "  0.         0.         0.03394159 0.20364955 0.03394159 0.03394159\n",
      "  0.02414972 0.         0.         0.03394159 0.03394159 0.\n",
      "  0.09659889 0.03394159 0.03394159 0.         0.03394159 0.03394159\n",
      "  0.02414972 0.         0.06788318 0.         0.         0.\n",
      "  0.         0.14489834 0.07244917 0.06788318 0.         0.04829945\n",
      "  0.03394159 0.06788318 0.02414972 0.03394159 0.         0.03394159\n",
      "  0.04829945 0.         0.         0.03394159 0.16970796 0.\n",
      "  0.         0.         0.06788318 0.06788318 0.         0.\n",
      "  0.03394159 0.03394159 0.03394159 0.04829945 0.03394159 0.06788318\n",
      "  0.         0.02414972 0.03394159 0.06788318 0.06788318 0.06788318\n",
      "  0.02414972 0.03394159 0.         0.         0.07244917 0.07244917\n",
      "  0.         0.         0.03394159 0.03394159 0.24149723 0.03394159\n",
      "  0.10182478 0.16970796 0.         0.26564695 0.03394159 0.\n",
      "  0.06788318 0.         0.03394159 0.03394159 0.03394159 0.12074861\n",
      "  0.         0.         0.03394159 0.06788318 0.03394159 0.03394159\n",
      "  0.03394159 0.07244917 0.03394159]]\n",
      "{'coach': 36, '00': 0, 'think': 206, 'went': 223, '24': 1, 'okay': 130, 'glad': 80, 'feeling': 67, 'good': 83, 'hopefully': 94, 'like': 109, 'little': 111, 'bit': 24, 'time': 209, 'make': 116, 'feel': 66, 'even': 59, 'prepared': 142, 'next': 127, 'first': 69, 'want': 221, 'comment': 38, 'maintaining': 115, 'enthusiasm': 56, 'know': 104, 'hard': 90, 're': 157, 'interacting': 99, 'avatar': 14, 'second': 177, 'pointed': 138, 'constantly': 40, 'probing': 145, 'go': 81, 'back': 18, 'text': 204, 'provide': 146, 'explanation': 64, 'support': 195, 'claim': 32, 'find': 68, 'really': 160, 'great': 85, 'thing': 205, 'keep': 100, 'would': 229, 'um': 215, 'advantageous': 5, 'moving': 123, 'forward': 71, 'two': 213, 'moment': 122, 'scaffolding': 176, 'student': 191, 'comprehension': 39, 'change': 31, 'answer': 9, 'give': 77, 'high': 93, 'quality': 151, 'descriptive': 47, 'feedback': 65, 'well': 222, 'savannah': 172, 'sure': 196, 'giving': 79, 'putting': 150, 'behavior': 22, 'let': 107, 'see': 178, 'ethan': 58, 'instance': 97, 'revived': 168, 'acceptable': 3, 'might': 119, 'saying': 174, 'one': 131, 'said': 170, 'excited': 63, 'talk': 200, 'type': 214, 'preferable': 141, 'kind': 102, 'providing': 147, 'summary': 194, 'mean': 118, 'given': 78, 'limited': 110, 'skipped': 182, 'question': 152, 'ava': 13, 'response': 167, 'probed': 144, 'based': 20, 'evidence': 61, 'scaffolded': 175, 'say': 173, 'guess': 87, 'something': 183, 'else': 52, 'awesome': 17, 'right': 169, 'get': 75, 'better': 23, 'brief': 26, 'work': 227, 'couple': 44, 'started': 186, 'tell': 202, 'appreciate': 10, 'able': 2, 'maintain': 114, 'pushing': 149, 'grinding': 86, 'throwing': 208, 'lot': 112, 'much': 124, 'also': 7, 'clear': 35, 'every': 60, 'students': 192, 'of': 129, 'course': 45, 'dev': 48, 'were': 224, 'engaging': 55, 'misbehavior': 120, 'immediately': 95, 'acknowledging': 4, 'recognizing': 161, 'important': 96, 'already': 6, 'lens': 106, 'seeing': 179, 'starting': 187, 'point': 137, 'quite': 155, 'throughout': 207, 'past': 134, 'stimulation': 188, 'various': 218, 'specific': 185, 'instruction': 98, 'attempt': 11, 'redirect': 162, 'beat': 21, 'boxing': 25, 'period': 135, 'please': 136, 'quiet': 154, 'stopped': 190, 'helpful': 91, 'sake': 171, 'simulation': 181, 'getting': 76, 'continue': 41, 'emphasize': 53, 'making': 117, 'redirections': 163, 'possible': 139, 'term': 203, 'discontinue': 49, 'succinct': 193, 'last': 105, 'example': 62, 'take': 198, 'trying': 212, 'engage': 54, 'conversation': 42, 'try': 211, 'talking': 201, 'respect': 166, 'another': 8, 'happened': 89, 'gave': 73, 'shorten': 180, 'why': 225, 'front': 72, 'understand': 216, 'coming': 37, 'day': 46, 'build': 28, 'rapport': 156, 'establish': 57, 'relationship': 164, 'practice': 140, 'miscommunication': 121, 'stop': 189, 'hey': 92, 'attention': 12, 'focused': 70, 'yeah': 230, 'aware': 15, 'letting': 108, 'or': 133, 'wan': 220, 'na': 125, 'use': 217, 'word': 226, 'low': 113, 'grade': 84, 'working': 228, 'taking': 199, 'away': 16, 'distracting': 50, 'soon': 184, 'caution': 30, 'real': 159, 'kid': 101, 'going': 82, 'push': 148, 'quick': 153, 'remember': 165, 'name': 126, 'cassidy': 29, 'pretend': 143, 'bring': 27, 'ready': 158, 'drum': 51, 'table': 197, 'bad': 19, 'class': 34, 'could': 43, 'non': 128, 'verbal': 219, 'gesture': 74, 'kinda': 103, 'clap': 33, 'hand': 88, 'together': 210, 'option': 132}\n",
      "[[0.16217019 0.05405673 0.         0.05405673 0.         0.05405673\n",
      "  0.         0.         0.         0.10811346 0.         0.\n",
      "  0.         0.16217019 0.05405673 0.         0.         0.05405673\n",
      "  0.15384723 0.         0.05405673 0.         0.03846181 0.\n",
      "  0.07692362 0.         0.         0.         0.         0.\n",
      "  0.         0.10811346 0.05405673 0.         0.         0.\n",
      "  0.42307989 0.         0.05405673 0.05405673 0.05405673 0.\n",
      "  0.         0.         0.         0.         0.         0.05405673\n",
      "  0.         0.         0.         0.         0.05405673 0.\n",
      "  0.         0.         0.03846181 0.         0.03846181 0.03846181\n",
      "  0.         0.05405673 0.         0.05405673 0.05405673 0.16217019\n",
      "  0.03846181 0.03846181 0.05405673 0.03846181 0.         0.05405673\n",
      "  0.         0.         0.         0.         0.         0.05405673\n",
      "  0.03846181 0.03846181 0.05405673 0.07692362 0.         0.11538542\n",
      "  0.         0.03846181 0.         0.05405673 0.         0.\n",
      "  0.03846181 0.         0.         0.05405673 0.03846181 0.\n",
      "  0.         0.03846181 0.         0.05405673 0.03846181 0.\n",
      "  0.11538542 0.         0.11538542 0.         0.         0.16217019\n",
      "  0.         0.38461808 0.05405673 0.07692362 0.         0.\n",
      "  0.         0.05405673 0.11538542 0.         0.05405673 0.19230904\n",
      "  0.         0.         0.05405673 0.10811346 0.         0.\n",
      "  0.         0.03846181 0.         0.         0.19230904 0.03846181\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05405673 0.         0.         0.05405673 0.03846181 0.\n",
      "  0.05405673 0.05405673 0.03846181 0.05405673 0.         0.\n",
      "  0.05405673 0.05405673 0.05405673 0.         0.         0.\n",
      "  0.         0.07692362 0.         0.         0.07692362 0.\n",
      "  0.         0.         0.         0.         0.         0.05405673\n",
      "  0.05405673 0.         0.03846181 0.         0.05405673 0.07692362\n",
      "  0.03846181 0.05405673 0.03846181 0.05405673 0.03846181 0.\n",
      "  0.         0.         0.05405673 0.10811346 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.03846181\n",
      "  0.         0.         0.05405673 0.05405673 0.03846181 0.\n",
      "  0.         0.         0.05405673 0.         0.         0.\n",
      "  0.16217019 0.07692362 0.19230904 0.         0.         0.15384723\n",
      "  0.         0.         0.         0.10811346 0.05405673 0.11538542\n",
      "  0.         0.         0.         0.         0.         0.03846181\n",
      "  0.16217019 0.10811346 0.         0.         0.         0.\n",
      "  0.         0.11538542 0.        ]\n",
      " [0.         0.         0.03312271 0.         0.03312271 0.\n",
      "  0.03312271 0.09936814 0.06624543 0.         0.06624543 0.03312271\n",
      "  0.03312271 0.         0.         0.06624543 0.06624543 0.\n",
      "  0.02356708 0.03312271 0.         0.03312271 0.09426833 0.06624543\n",
      "  0.02356708 0.03312271 0.03312271 0.03312271 0.03312271 0.13249085\n",
      "  0.03312271 0.         0.         0.03312271 0.03312271 0.03312271\n",
      "  0.35350625 0.03312271 0.         0.         0.         0.03312271\n",
      "  0.06624543 0.06624543 0.03312271 0.03312271 0.03312271 0.\n",
      "  0.03312271 0.03312271 0.03312271 0.03312271 0.         0.03312271\n",
      "  0.06624543 0.03312271 0.02356708 0.03312271 0.11783542 0.02356708\n",
      "  0.03312271 0.         0.03312271 0.         0.         0.\n",
      "  0.04713417 0.02356708 0.         0.07070125 0.09936814 0.\n",
      "  0.03312271 0.03312271 0.03312271 0.16561357 0.03312271 0.\n",
      "  0.02356708 0.02356708 0.         0.02356708 0.06624543 0.02356708\n",
      "  0.03312271 0.02356708 0.03312271 0.         0.03312271 0.03312271\n",
      "  0.02356708 0.03312271 0.03312271 0.         0.04713417 0.03312271\n",
      "  0.03312271 0.02356708 0.06624543 0.         0.04713417 0.03312271\n",
      "  0.11783542 0.03312271 0.11783542 0.03312271 0.03312271 0.\n",
      "  0.03312271 0.30637208 0.         0.04713417 0.16561357 0.03312271\n",
      "  0.03312271 0.         0.02356708 0.06624543 0.         0.02356708\n",
      "  0.13249085 0.06624543 0.         0.         0.06624543 0.03312271\n",
      "  0.03312271 0.04713417 0.03312271 0.03312271 0.07070125 0.11783542\n",
      "  0.03312271 0.03312271 0.03312271 0.03312271 0.16561357 0.06624543\n",
      "  0.         0.13249085 0.06624543 0.         0.02356708 0.03312271\n",
      "  0.         0.         0.02356708 0.         0.03312271 0.03312271\n",
      "  0.         0.         0.         0.03312271 0.19873628 0.03312271\n",
      "  0.03312271 0.02356708 0.03312271 0.03312271 0.09426833 0.03312271\n",
      "  0.03312271 0.03312271 0.03312271 0.03312271 0.06624543 0.\n",
      "  0.         0.19873628 0.07070125 0.06624543 0.         0.04713417\n",
      "  0.02356708 0.         0.04713417 0.         0.02356708 0.03312271\n",
      "  0.03312271 0.06624543 0.         0.         0.03312271 0.16561357\n",
      "  0.06624543 0.06624543 0.03312271 0.03312271 0.03312271 0.04713417\n",
      "  0.03312271 0.06624543 0.         0.         0.02356708 0.03312271\n",
      "  0.06624543 0.06624543 0.         0.06624543 0.03312271 0.03312271\n",
      "  0.         0.07070125 0.07070125 0.03312271 0.03312271 0.23567083\n",
      "  0.03312271 0.09936814 0.16561357 0.         0.         0.25923791\n",
      "  0.03312271 0.06624543 0.03312271 0.03312271 0.03312271 0.11783542\n",
      "  0.         0.         0.03312271 0.06624543 0.03312271 0.03312271\n",
      "  0.03312271 0.07070125 0.03312271]]\n"
     ]
    }
   ],
   "source": [
    "def get_cosine_sim(*strs): \n",
    "    vectors = [t for t in get_vectors(*strs)]\n",
    "    return cosine_similarity(vectors)\n",
    "    \n",
    "def get_vectors(*strs):\n",
    "    text = [t for t in strs]\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(text)\n",
    "    print(vectorizer.vocabulary_ )\n",
    "    print(vectorizer.transform(text).toarray())\n",
    "    return vectorizer.transform(text).toarray()\n",
    "sim_fall = get_cosine_sim(doc1_text_stopwords_removed, doc2_text_stopwords_removed)\n",
    "sim_year = get_cosine_sim(doc1_text_stopwords_removed, doc3_text_stopwords_removed)\n",
    "sim_year2 = get_cosine_sim(doc2_text_stopwords_removed, doc3_text_stopwords_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "between fall sessions:  0.6014700072309651\n",
      "between one fall and one spring:  0.4237964608088539\n"
     ]
    }
   ],
   "source": [
    "#Note: closer documents = higher cosine similarity\n",
    "print('between fall sessions: ', sim_fall[0][1])\n",
    "print('between one fall and one spring: ', sim_year[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spacy]",
   "language": "python",
   "name": "conda-env-spacy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
